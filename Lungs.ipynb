{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "CatDog.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChrisGold/DM873-Project-2/blob/main/Lungs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eqk7mmzqrbRR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a2755cd-1bf3-4b77-c33f-ab64fb7d1364"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muOonLyATy6k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ea74cd7-50af-46c1-e607-486a594a47c9"
      },
      "source": [
        "! ls /content/drive/My\\ Drive/data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "allData  eval  train  val\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PskhqnFfxZc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20d26e6a-3faf-41fc-ec17-a1df2ecbe3c4"
      },
      "source": [
        "import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.layers import Conv2D, MaxPool2D, Input, Dropout, experimental, AveragePooling2D, GlobalAveragePooling2D\n",
        "\n",
        "#we use a quite large patience for early stopping, because we have a lot of fluctuation.\n",
        "\n",
        "patience = 10\n",
        "imageSizeX = 224\n",
        "imageSizeY = 224\n",
        "batchSize = 32\n",
        "\n",
        "TrainDataGen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.3,\n",
        "    height_shift_range=0.3,\n",
        "    shear_range=0.3,\n",
        "    zoom_range=0.3,\n",
        "    horizontal_flip=True,fill_mode = 'nearest',\n",
        "    \n",
        "    channel_shift_range=13,data_format='channels_last',\n",
        ")\n",
        "\n",
        "ValDataGen=ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "\n",
        "TrainData = ValDataGen.flow_from_directory(batch_size = batchSize,\n",
        "                                                 directory = 'drive/My Drive/lung/train/',\n",
        "                                                 shuffle = True,\n",
        "                                                 target_size = (imageSizeX, imageSizeY), \n",
        "                                                 subset = \"training\",\n",
        "                                                 color_mode=\"grayscale\",\n",
        "                                                 class_mode = 'binary')\n",
        "\n",
        "ValData = ValDataGen.flow_from_directory(batch_size = batchSize,\n",
        "                                                 directory = 'drive/My Drive/lung/val/',\n",
        "                                                 shuffle = True,\n",
        "                                                 target_size = (imageSizeX, imageSizeY), \n",
        "                                                 subset = \"training\",\n",
        "                                                 color_mode=\"grayscale\",\n",
        "                                                 class_mode = 'binary')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# stops the training at given training accuracy\n",
        "class myCallback(keras.callbacks.Callback): \n",
        "    targetAccuracy = 0.9\n",
        "    def on_epoch_end(self, epoch, logs={}): \n",
        "        if(logs.get('accuracy') > (self.targetAccuracy)):   \n",
        "            self.model.stop_training = True\n",
        "\n",
        "            \n",
        "\n",
        "\n",
        "cb = keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss', min_delta=0, patience=patience, verbose=0, mode='auto',\n",
        "    baseline=None, restore_best_weights=True\n",
        ")\n",
        "\n",
        "\n",
        "model = keras.Sequential([\n",
        "\n",
        "    \n",
        "    layers.Conv2D(32, 3, padding='same', activation='relu', input_shape=(imageSizeX, imageSizeY, 1)),\n",
        "    layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "    layers.MaxPooling2D(2,2),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.4),\n",
        "\n",
        "\n",
        "    layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "    layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "    layers.MaxPooling2D(2,2),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.4),\n",
        "\n",
        "    layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "    layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "    layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "    layers.MaxPooling2D(2,2),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.4),\n",
        "\n",
        "    layers.Conv2D(128, 3, padding='same', activation='relu'),\n",
        "    layers.Conv2D(128, 3, padding='same', activation='relu'),\n",
        "    layers.Conv2D(128, 3, padding='same', activation='relu'),\n",
        "    layers.MaxPooling2D(2,2),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.4),\n",
        "\n",
        "    layers.Conv2D(256, 3, padding='same', activation='relu'),\n",
        "    layers.Conv2D(256, 3, padding='same', activation='relu'),\n",
        "    layers.Conv2D(256, 3, padding='same', activation='relu'),\n",
        "    layers.MaxPooling2D(2,2),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.4),\n",
        "\n",
        "    layers.Conv2D(256, 3, padding='same', activation='relu'),\n",
        "    layers.Conv2D(256, 3, padding='same', activation='relu'),\n",
        "    layers.Conv2D(256, 3, padding='same', activation='relu'),\n",
        "    layers.GlobalMaxPooling2D(),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.4),\n",
        "    \n",
        "    layers.Flatten(),\n",
        "    layers.Dense(512, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "\n",
        "    layers.Dense(512, activation='relu'),\n",
        "    layers.Dropout(0.5),    \n",
        "\n",
        "    layers.Dense(1, activation ='sigmoid')\n",
        "])\n",
        "\n",
        "\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history =model.fit(TrainData, \n",
        "                epochs=1000, #we stop training the model with early stopping\n",
        "                validation_data=ValData,\n",
        "                callbacks=[cb])\n",
        "\n",
        "\n",
        "# after the training on the training dataset is done, we attempt to learn on the validation data + training data\n",
        "# until we reach the same training accuracy as we did on the training data\n",
        "\n",
        "#allData = TrainDataGen.flow_from_directory(batch_size=batchSize,\n",
        "#                                                 directory='drive/My Drive/data/allData/',\n",
        "#                                                 shuffle=True,\n",
        "#                                                 target_size=(imageSizeX, imageSizeY), \n",
        "#                                                 subset=\"training\",\n",
        "#                                                 class_mode='binary')\n",
        "\n",
        "\n",
        "#cb = myCallback()\n",
        "#cb.targetAccuracy = history.history['accuracy'][-(patience+1)]\n",
        "#print(cb.targetAccuracy)\n",
        "#\n",
        "#model.fit(allData, \n",
        "#                    epochs=1000, \n",
        "#                    callbacks=[cb])\n",
        "\n",
        "model.save('lungs_auto.h5')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2382 images belonging to 2 classes.\n",
            "Found 300 images belonging to 2 classes.\n",
            "Epoch 1/1000\n",
            "75/75 [==============================] - 40s 537ms/step - loss: 0.4503 - accuracy: 0.8363 - val_loss: 1.6228 - val_accuracy: 0.5000\n",
            "Epoch 2/1000\n",
            "75/75 [==============================] - 39s 524ms/step - loss: 0.2459 - accuracy: 0.9148 - val_loss: 4.0636 - val_accuracy: 0.5000\n",
            "Epoch 3/1000\n",
            "75/75 [==============================] - 39s 525ms/step - loss: 0.1789 - accuracy: 0.9307 - val_loss: 5.8914 - val_accuracy: 0.5000\n",
            "Epoch 4/1000\n",
            "75/75 [==============================] - 39s 525ms/step - loss: 0.1552 - accuracy: 0.9467 - val_loss: 1.7857 - val_accuracy: 0.6500\n",
            "Epoch 5/1000\n",
            "75/75 [==============================] - 40s 530ms/step - loss: 0.1361 - accuracy: 0.9521 - val_loss: 0.7007 - val_accuracy: 0.8633\n",
            "Epoch 6/1000\n",
            "75/75 [==============================] - 40s 528ms/step - loss: 0.1065 - accuracy: 0.9656 - val_loss: 0.5145 - val_accuracy: 0.8967\n",
            "Epoch 7/1000\n",
            "75/75 [==============================] - 39s 526ms/step - loss: 0.1158 - accuracy: 0.9593 - val_loss: 0.7634 - val_accuracy: 0.8900\n",
            "Epoch 8/1000\n",
            "75/75 [==============================] - 39s 524ms/step - loss: 0.0872 - accuracy: 0.9681 - val_loss: 0.2545 - val_accuracy: 0.9567\n",
            "Epoch 9/1000\n",
            "75/75 [==============================] - 39s 524ms/step - loss: 0.0874 - accuracy: 0.9710 - val_loss: 0.3513 - val_accuracy: 0.9700\n",
            "Epoch 10/1000\n",
            "75/75 [==============================] - 40s 527ms/step - loss: 0.0702 - accuracy: 0.9719 - val_loss: 0.0428 - val_accuracy: 0.9933\n",
            "Epoch 11/1000\n",
            "75/75 [==============================] - 39s 527ms/step - loss: 0.0773 - accuracy: 0.9794 - val_loss: 0.4270 - val_accuracy: 0.9367\n",
            "Epoch 12/1000\n",
            "75/75 [==============================] - 39s 524ms/step - loss: 0.0635 - accuracy: 0.9790 - val_loss: 0.1342 - val_accuracy: 0.9767\n",
            "Epoch 13/1000\n",
            "75/75 [==============================] - 40s 529ms/step - loss: 0.0646 - accuracy: 0.9798 - val_loss: 1.0145 - val_accuracy: 0.8833\n",
            "Epoch 14/1000\n",
            "75/75 [==============================] - 39s 525ms/step - loss: 0.0536 - accuracy: 0.9803 - val_loss: 0.3392 - val_accuracy: 0.9633\n",
            "Epoch 15/1000\n",
            "26/75 [=========>....................] - ETA: 22s - loss: 0.0284 - accuracy: 0.9868"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWghBBnhgOIX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa454c78-1d60-46b9-fc6c-7d4e0fd8c98f"
      },
      "source": [
        "testDataGen=ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "test = testDataGen.flow_from_directory(batch_size = batchSize,\n",
        "                                                 directory = 'drive/My Drive/lung/val/',\n",
        "                                                 shuffle = False,\n",
        "                                                 target_size = (imageSizeX, imageSizeY), \n",
        "                                                 subset = \"training\",\n",
        "                                                 color_mode=\"grayscale\",\n",
        "                                                 class_mode = 'binary')\n",
        "\n",
        "#modelLoad = keras.models.load_model('cats_dogs_auto2.h5')\n",
        "model.evaluate(test)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 300 images belonging to 2 classes.\n",
            "20/20 [==============================] - 6s 303ms/step - loss: 1.5666 - accuracy: 0.8176\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.5666486024856567, 0.8175895810127258]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    }
  ]
}